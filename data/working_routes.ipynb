{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d948c5-2735-436c-81d0-d7dacf91e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "# Base directory containing GTFS feeds\n",
    "base_dir = \"gtfs\"\n",
    "\n",
    "# Get all subdirectories in base directory\n",
    "sub_dirs = [os.path.join(base_dir, d) for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "\n",
    "# Lists to store processed stops and routes\n",
    "stops_features = []\n",
    "routes_features = []\n",
    "\n",
    "for sub_dir in sub_dirs:\n",
    "    feed_name = os.path.basename(sub_dir)\n",
    "    print(f\"Processing feed: {feed_name}\")\n",
    "\n",
    "    # ---------------------\n",
    "    # Load routes.txt (route metadata)\n",
    "    # ---------------------\n",
    "    routes_file = os.path.join(sub_dir, \"routes.txt\")\n",
    "    if os.path.exists(routes_file):\n",
    "        routes_df = pd.read_csv(routes_file, usecols=[\"route_id\", \"route_color\"], dtype={\"route_id\": str, \"route_color\": str})\n",
    "        routes_df[\"route_color\"] = routes_df[\"route_color\"].fillna(\"000000\").apply(lambda x: f\"#{x.zfill(6)}\")  # Ensure HEX format\n",
    "    else:\n",
    "        print(f\"Missing routes.txt in {sub_dir}\")\n",
    "        routes_df = pd.DataFrame(columns=[\"route_id\", \"route_color\"])\n",
    "\n",
    "    # ---------------------\n",
    "    # Load trips.txt (trip_id → route_id mapping)\n",
    "    # ---------------------\n",
    "    trips_file = os.path.join(sub_dir, \"trips.txt\")\n",
    "    if os.path.exists(trips_file):\n",
    "        trips_df = pd.read_csv(trips_file, usecols=[\"trip_id\", \"route_id\", \"shape_id\"], dtype={\"trip_id\": str, \"route_id\": str, \"shape_id\": str}).dropna()\n",
    "        #trips_df = trips_df.drop_duplicates(subset=[\"shape_id\", \"route_id\"])\n",
    "    else:\n",
    "        print(f\"Missing trips.txt in {sub_dir}\")\n",
    "        trips_df = pd.DataFrame(columns=[\"trip_id\", \"route_id\", \"shape_id\"])\n",
    "\n",
    "    # ---------------------\n",
    "    # Process Routes (shapes.txt)\n",
    "    # ---------------------\n",
    "    shapes_file = os.path.join(sub_dir, \"shapes.txt\")\n",
    "    if os.path.exists(shapes_file):\n",
    "        shapes_df = pd.read_csv(shapes_file, usecols=[\"shape_id\", \"shape_pt_lat\", \"shape_pt_lon\", \"shape_pt_sequence\"], dtype={\"shape_id\": str})\n",
    "\n",
    "        # Merge with trips_df to get route metadata\n",
    "        shapes_merged_df = shapes_df.merge(trips_df, on=\"shape_id\", how=\"left\")\n",
    "\n",
    "        # Aggregate to create LineStrings\n",
    "        shapes_grouped = shapes_merged_df.groupby(\"shape_id\").agg({\n",
    "            \"shape_pt_lon\": list,\n",
    "            \"shape_pt_lat\": list,\n",
    "            \"route_id\": \"first\"\n",
    "        }).reset_index()\n",
    "\n",
    "        # Convert grouped points into LineStrings\n",
    "        shapes_grouped[\"geometry\"] = shapes_grouped.apply(lambda row: LineString(zip(row[\"shape_pt_lon\"], row[\"shape_pt_lat\"])), axis=1)\n",
    "        \n",
    "        # Assign route colors\n",
    "        shapes_grouped = shapes_grouped.merge(routes_df, on=\"route_id\", how=\"left\").fillna(\"#000000\")\n",
    "        \n",
    "        # Add feed name\n",
    "        shapes_grouped[\"feed\"] = feed_name\n",
    "\n",
    "        # Convert to dictionary format\n",
    "        routes_features.extend(shapes_grouped.to_dict(orient=\"records\"))\n",
    "    else:\n",
    "        print(f\"Missing shapes.txt in {sub_dir}\")\n",
    "\n",
    "    # ---------------------\n",
    "    # Process Stops (stops.txt)\n",
    "    # ---------------------\n",
    "    stops_file = os.path.join(sub_dir, \"stops.txt\")\n",
    "    if os.path.exists(stops_file):\n",
    "        stops_df = pd.read_csv(stops_file, dtype={\"stop_id\": str, \"stop_name\": str, \"stop_lat\": float, \"stop_lon\": float})\n",
    "    else:\n",
    "        print(f\"Missing stops.txt in {sub_dir}\")\n",
    "        continue\n",
    "\n",
    "    # ---------------------\n",
    "    # Load stop_times.txt (stop_id → trip_id mapping)\n",
    "    # ---------------------\n",
    "    stop_times_file = os.path.join(sub_dir, \"stop_times.txt\")\n",
    "    if os.path.exists(stop_times_file):\n",
    "        stop_times_df = pd.read_csv(stop_times_file, usecols=[\"stop_id\", \"trip_id\"], dtype={\"stop_id\": str, \"trip_id\": str}).dropna()\n",
    "    else:\n",
    "        print(f\"Missing stop_times.txt in {sub_dir}\")\n",
    "        continue\n",
    "\n",
    "    # Merge stop_times with trips to get route_id per stop\n",
    "    stop_routes_df = stop_times_df.merge(trips_df, on=\"trip_id\", how=\"left\").drop(columns=[\"trip_id\"])\n",
    "\n",
    "    # ---------------------\n",
    "    # Aggregate all routes per stop\n",
    "    # ---------------------\n",
    "    stop_routes_grouped = stop_routes_df.groupby(\"stop_id\")[\"route_id\"].unique().reset_index()\n",
    "\n",
    "    # Convert route_id list to a comma-separated string\n",
    "    stop_routes_grouped[\"routes\"] = stop_routes_grouped[\"route_id\"].apply(\n",
    "        lambda x: \",\".join(sorted(map(str, x))) if pd.notnull(x).all() else \"\"\n",
    "    )\n",
    "\n",
    "    stop_routes_grouped = stop_routes_grouped.drop(columns=[\"route_id\"])\n",
    "\n",
    "\n",
    "    # Merge stops with route data\n",
    "    stops_merged_df = stops_df.merge(stop_routes_grouped, on=\"stop_id\", how=\"left\").fillna(\"\")\n",
    "\n",
    "    # Assign route colors\n",
    "    def get_primary_route_color(route_list):\n",
    "        if not route_list:\n",
    "            return \"#000000\"\n",
    "        first_route = route_list.split(\",\")[0] if \",\" in route_list else route_list\n",
    "        color = routes_df[routes_df[\"route_id\"] == first_route][\"route_color\"].values\n",
    "        return color[0] if len(color) > 0 else \"#000000\"\n",
    "\n",
    "    stops_merged_df[\"route_color\"] = stops_merged_df[\"routes\"].apply(get_primary_route_color)\n",
    "\n",
    "    # Convert to GeoJSON format\n",
    "    stops_merged_df[\"geometry\"] = stops_merged_df.apply(lambda row: Point(row[\"stop_lon\"], row[\"stop_lat\"]), axis=1)\n",
    "    stops_merged_df[\"feed\"] = feed_name\n",
    "\n",
    "    # Convert to dictionary format\n",
    "    stops_features.extend(stops_merged_df.to_dict(orient=\"records\"))\n",
    "\n",
    "# ---------------------\n",
    "# Export GeoJSON files\n",
    "# ---------------------\n",
    "if routes_features:\n",
    "    routes_gdf = gpd.GeoDataFrame(routes_features, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "    routes_gdf.to_file(\"routes.geojson\", driver=\"GeoJSON\")\n",
    "    print(\"Created routes.geojson\")\n",
    "else:\n",
    "    print(\"No route data found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67aac96-6fcf-417c-bc08-c7b06cf6b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.tail()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onebusmap",
   "language": "python",
   "name": "onebusmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
